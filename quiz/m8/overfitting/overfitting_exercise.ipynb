{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Exercise\n",
    "In this exercise, we'll build a model that, as you'll see, dramatically overfits the training data. This will allow you to see what overfitting can \"look like\" in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use gradient boosted trees. In order to implement this model, we'll use the XGBoost package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a few helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows in a dataframe\n",
    "def nrow(df): \n",
    "    return(len(df.index))\n",
    "\n",
    "# number of columns in a dataframe\n",
    "def ncol(df): \n",
    "    return(len(df.columns))\n",
    "\n",
    "# flatten nested lists/arrays\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# combine multiple arrays into a single list\n",
    "def c(*args):\n",
    "    return(flatten([item for item in args]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we're going to try to predict the returns of the S&P 500 ETF. This may be a futile endeavor, since many experts consider the S&P 500 to be essentially unpredictable, but it will serve well for the purpose of this exercise. The following cell loads the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SPYZ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data file has four columns, `Date`, `Close`, `Volume` and `Return`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>146.8750</td>\n",
       "      <td>3172700</td>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>145.4375</td>\n",
       "      <td>8164300</td>\n",
       "      <td>-0.009787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>139.7500</td>\n",
       "      <td>8089800</td>\n",
       "      <td>-0.039106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>140.0000</td>\n",
       "      <td>12177900</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>137.7500</td>\n",
       "      <td>6227200</td>\n",
       "      <td>-0.016071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Close    Volume    Return\n",
       "0  1999-12-31  146.8750   3172700  0.001598\n",
       "1  2000-01-03  145.4375   8164300 -0.009787\n",
       "2  2000-01-04  139.7500   8089800 -0.039106\n",
       "3  2000-01-05  140.0000  12177900  0.001789\n",
       "4  2000-01-06  137.7500   6227200 -0.016071"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nrow(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll form our predictors/features. In the cells below, we create four types of features. We also use a parameter, `K`, to set the number of each type of feature to build. With a `K` of 25, 100 features will be created. This should already seem like a lot of features, and alert you to the potential that the model will be overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y\n",
       "0  0.001598\n",
       "1 -0.009787\n",
       "2 -0.039106\n",
       "3  0.001789\n",
       "4 -0.016071"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = []\n",
    "\n",
    "# we'll create a new DataFrame to hold the data that we'll use to train the model\n",
    "# we'll create it from the `Return` column in the original DataFrame, but rename that column `y`\n",
    "model_df = pd.DataFrame(data = df['Return']).rename(columns = {\"Return\" : \"y\"})\n",
    "\n",
    "# IMPORTANT: this sets how many of each of the following four predictors to create\n",
    "K = 25\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you write the code to create the four types of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for L in range(1,K+1): \n",
    "    # this predictor is just the return L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `R1`, `R2`, etc.\n",
    "    pR = \"\".join([\"R\",str(L)]) \n",
    "    predictors.append(pR)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the return from L days before to the ith row of this predictor in `model_df`\n",
    "        model_df.loc[i, pR] = df.loc[i-L, 'Return']\n",
    "\n",
    "    # this predictor is the return L days ago, squared, where L goes from 1 to K\n",
    "    # these predictors will be named `Rsq1`, `Rsq2`, etc.\n",
    "    pR2 = \"\".join([\"Rsq\",str(L)])\n",
    "    predictors.append(pR2)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the squared return from L days before to the ith row of this predictor \n",
    "        # in `model_df`\n",
    "        model_df.loc[i, pR2] = (df.loc[i-L, 'Return'])** 2\n",
    "\n",
    "    # this predictor is the log volume L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `V1`, `V2`, etc.\n",
    "    pV = \"\".join([\"V\",str(L)])\n",
    "    predictors.append(pV)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the log of the volume from L days before to the ith row of this predictor \n",
    "        # in `model_df`\n",
    "        # Add 1 to the volume before taking the log\n",
    "        model_df.loc[i, pV] = np.log(df.loc[i-L, 'Volume'])\n",
    "\n",
    "    # this predictor is the product of the return and the log volume from L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `RV1`, `RV2`, etc.\n",
    "    pRV = \"\".join([\"RV\",str(L)])\n",
    "    predictors.append(pRV)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the product of the return and the log volume from L days before to the\n",
    "        # ith row of this predictor in `model_df`\n",
    "        model_df.loc[i, pRV] = model_df.loc[i, pR] * model_df.loc[i, pV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the predictors we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rsq1</th>\n",
       "      <th>V1</th>\n",
       "      <th>RV1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Rsq2</th>\n",
       "      <th>V2</th>\n",
       "      <th>RV2</th>\n",
       "      <th>R3</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>RV23</th>\n",
       "      <th>R24</th>\n",
       "      <th>Rsq24</th>\n",
       "      <th>V24</th>\n",
       "      <th>RV24</th>\n",
       "      <th>R25</th>\n",
       "      <th>Rsq25</th>\n",
       "      <th>V25</th>\n",
       "      <th>RV25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016304</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>15.892349</td>\n",
       "      <td>-0.234024</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>16.198698</td>\n",
       "      <td>-0.121956</td>\n",
       "      <td>-0.018688</td>\n",
       "      <td>...</td>\n",
       "      <td>15.959990</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>15.695540</td>\n",
       "      <td>-0.145995</td>\n",
       "      <td>0.026421</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>16.209370</td>\n",
       "      <td>0.428273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>16.221058</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>15.892349</td>\n",
       "      <td>-0.234024</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>...</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>15.959990</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>15.695540</td>\n",
       "      <td>-0.145995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>15.929221</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>16.221058</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>...</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>15.959990</td>\n",
       "      <td>0.076664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15.387039</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>15.929221</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>...</td>\n",
       "      <td>15.858171</td>\n",
       "      <td>-0.178954</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>15.494959</td>\n",
       "      <td>0.529838</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15.387039</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>...</td>\n",
       "      <td>16.562480</td>\n",
       "      <td>-0.054770</td>\n",
       "      <td>-0.011285</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>15.858171</td>\n",
       "      <td>-0.178954</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y        R1      Rsq1         V1       RV1        R2      Rsq2  \\\n",
       "100  0.016304 -0.014726  0.000217  15.892349 -0.234024 -0.007529  0.000057   \n",
       "101 -0.017157  0.016304  0.000266  16.221058  0.264474 -0.014726  0.000217   \n",
       "102  0.001133 -0.017157  0.000294  15.929221 -0.273290  0.016304  0.000266   \n",
       "103  0.034194  0.001133  0.000001  15.387039  0.017437 -0.017157  0.000294   \n",
       "104  0.000657  0.034194  0.001169  15.494959  0.529838  0.001133  0.000001   \n",
       "\n",
       "            V2       RV2        R3    ...           V23      RV23       R24  \\\n",
       "100  16.198698 -0.121956 -0.018688    ...     15.959990  0.076664 -0.009302   \n",
       "101  15.892349 -0.234024 -0.007529    ...     16.372203 -0.177882  0.004804   \n",
       "102  16.221058  0.264474 -0.014726    ...     16.461827  0.683503 -0.010865   \n",
       "103  15.929221 -0.273290  0.016304    ...     15.858171 -0.178954  0.041520   \n",
       "104  15.387039  0.017437 -0.017157    ...     16.562480 -0.054770 -0.011285   \n",
       "\n",
       "        Rsq24        V24      RV24       R25     Rsq25        V25      RV25  \n",
       "100  0.000087  15.695540 -0.145995  0.026421  0.000698  16.209370  0.428273  \n",
       "101  0.000023  15.959990  0.076664 -0.009302  0.000087  15.695540 -0.145995  \n",
       "102  0.000118  16.372203 -0.177882  0.004804  0.000023  15.959990  0.076664  \n",
       "103  0.001724  16.461827  0.683503 -0.010865  0.000118  16.372203 -0.177882  \n",
       "104  0.000127  15.858171 -0.178954  0.041520  0.001724  16.461827  0.683503  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.iloc[100:105,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df2 = pd.DataFrame(data = df['Return']).rename(columns = {\"Return\" : \"y\"})\n",
    "\n",
    "for L in range(1,K+1): \n",
    "    # this predictor is just the return L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `R1`, `R2`, etc.\n",
    "    pR = \"\".join([\"R\",str(L)]) \n",
    "    model_df2[pR] = df['Return'].shift(periods=L)\n",
    "\n",
    "    # this predictor is the return L days ago, squared, where L goes from 1 to K\n",
    "    # these predictors will be named `Rsq1`, `Rsq2`, etc.\n",
    "    pR2 = \"\".join([\"Rsq\",str(L)])\n",
    "    model_df2[pR2] = (df['Return'].shift(L))** 2\n",
    "\n",
    "    # this predictor is the log volume L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `V1`, `V2`, etc.\n",
    "    pV = \"\".join([\"V\",str(L)])\n",
    "    model_df2[pV] = np.log(df['Volume'].shift(L))\n",
    "\n",
    "    # this predictor is the product of the return and the log volume from L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `RV1`, `RV2`, etc.\n",
    "    pRV = \"\".join([\"RV\",str(L)])\n",
    "    model_df2[pRV] = model_df2[pR] * model_df2[pV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a DataFrame that holds the recent volatility of the ETF's returns, as measured by the standard deviation of a sliding window of the past 20 days' returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df = pd.DataFrame(data = df[['Return']])\n",
    "\n",
    "for i in range(K+1,n): \n",
    "    # TODO: create the code to assign the standard deviation of the return from the time period starting \n",
    "    # 20 days before day i, up to the day before day i, to the ith row of `vol_df`\n",
    "    vol_df.loc[i, 'vol'] = vol_df.loc[(i-20):(i-1), 'Return'].std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df2 = pd.DataFrame(data = df[['Return']])\n",
    "vol_df2['vol'] = vol_df2['Return'].rolling(20).std().shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Return</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.013409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.013969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.014371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.014372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.016202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Return       vol\n",
       "100  0.016304  0.013409\n",
       "101 -0.017157  0.013969\n",
       "102  0.001133  0.014371\n",
       "103  0.034194  0.014372\n",
       "104  0.000657  0.016202"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_df.iloc[100:105,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we can start thinking about training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training, we'll use all the data except for the first K days, for which the predictors' values are NaNs\n",
    "model = model_df.iloc[K:n,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, first split the data into train and test sets, and then split off the targets from the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_size = 2.0/3.0\n",
    "breakpoint = round(nrow(model) * train_size)\n",
    "\n",
    "# TODO: fill in the code to split off the chunk of data up to the breakpoint as the training set, and\n",
    "# assign the rest as the test set.\n",
    "training_data = model.iloc[0:breakpoint]\n",
    "test_data = model.iloc[breakpoint:]\n",
    "\n",
    "# TODO: Split training data and test data into targets (Y) and predictors (X), for the training set and the test set\n",
    "X_train = training_data.drop(columns=['y'])\n",
    "Y_train = training_data['y']\n",
    "X_test = test_data.drop(columns=['y'])\n",
    "Y_test = test_data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we have our data, let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMatrix is a internal data structure that used by XGBoost which is optimized for both memory efficiency \n",
    "# and training speed. \n",
    "dtrain = xgb.DMatrix(X_train, Y_train)\n",
    "\n",
    "# Train the XGBoost model\n",
    "param = { 'max_depth':20, 'silent':1 }\n",
    "num_round = 20\n",
    "xgModel = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the returns for the S&P 500 ETF in both the train and test periods. If the model is successful, what should the train and test accuracies look like? What would be a key sign that the model has overfit the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: Before you run the next cell, write down what you expect to see if the model is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions on the test data\n",
    "preds_train = xgModel.predict(xgb.DMatrix(X_train))\n",
    "preds_test = xgModel.predict(xgb.DMatrix(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at the mean squared error of the predictions on the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.621386796360016e-06"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate the mean squared error on the training set\n",
    "msetrain = sum((preds_train-Y_train)**2)/len(preds_train)\n",
    "msetrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.424369347560127e-05"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate the mean squared error on the test set\n",
    "msetest = sum((preds_test-Y_test)**2)/len(preds_test)\n",
    "msetest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the mean squared error on the test set is an order of magnitude greater than on the training set. Not a good sign. Now let's do some quick calculations to gauge how this would translate into performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine prediction arrays into a single list\n",
    "predictions = c(preds_train, preds_test)\n",
    "responses = c(Y_train, Y_test)\n",
    "\n",
    "# as a holding size, we'll take predicted return divided by return variance\n",
    "# this is mean-variance optimization with a single asset\n",
    "vols = vol_df.loc[K:n,'vol']\n",
    "position_size = predictions / vols ** 2\n",
    "\n",
    "# TODO: Calculate pnl. Pnl in each time period is holding * realized return.\n",
    "performance = position_size * responses\n",
    "\n",
    "# plot simulated performance\n",
    "plt.plot(np.cumsum(performance))\n",
    "plt.ylabel('Simulated Performance')\n",
    "plt.axvline(x=breakpoint, c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simulated returns accumulate throughout the training period, but they are absolutely flat in the testing period. The model has no predictive power whatsoever in the out-of-sample period.\n",
    "\n",
    "Can you think of a few reasons our simulation of performance is unrealistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Answer the above question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you need a little assistance, check out the [solution](overfitting_exercise_solution.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
